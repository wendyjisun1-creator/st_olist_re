import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import json
from datetime import datetime

# íŽ˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Olist í†µí•© ì „ëžµ ëŒ€ì‹œë³´ë“œ", layout="wide")

# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ìºì‹± ì‚¬ìš©)
@st.cache_data
def load_all_dashboard_data():
    # ë°ì´í„° í´ë” í›„ë³´êµ°
    possible_paths = [
        r'c:\fcicb6\data\OLIST_V.2\DATA_PARQUET',
        os.path.join(os.path.dirname(__file__), 'DATA_PARQUET'),
        os.path.join(os.path.dirname(__file__), 'data'),
        os.path.dirname(__file__),
    ]
    
    base_path = None
    for p in possible_paths:
        if os.path.exists(p) and (os.path.exists(os.path.join(p, 'proc_olist_orders_dataset.parquet')) or 
                                os.path.exists(os.path.join(p, 'proc_olist_orders_dataset.csv'))):
            base_path = p
            break
            
    if not base_path:
        st.error("í•µì‹¬ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    
    def read_df(name):
        pq = os.path.join(base_path, f'{name}.parquet')
        csv = os.path.join(base_path, f'{name}.csv')
        if os.path.exists(pq): return pd.read_parquet(pq)
        if os.path.exists(csv): return pd.read_csv(csv)
        return pd.DataFrame()

    # ë°ì´í„° ë¡œë”©
    orders = read_df('proc_olist_orders_dataset')
    items = read_df('proc_olist_order_items_dataset')
    reviews = read_df('proc_olist_order_reviews_dataset')
    payments = read_df('proc_olist_order_payments_dataset')
    customers = read_df('proc_olist_customers_dataset')
    products = read_df('proc_olist_products_dataset')
    
    # ì‹œê°„ ë°ì´í„° ë³€í™˜
    date_cols = ['order_purchase_timestamp', 'order_delivered_customer_date', 'order_estimated_delivery_date']
    for col in date_cols:
        if col in orders.columns and not pd.api.types.is_datetime64_any_dtype(orders[col]):
            orders[col] = pd.to_datetime(orders[col])
            
    # ê¸°ë³¸ ì „ì²˜ë¦¬: ì§€ì—° ì¼ìˆ˜ ë° ë°°ì†¡ ê¸°ê°„
    orders['delay_days'] = (orders['order_delivered_customer_date'] - orders['order_estimated_delivery_date']).dt.days
    orders['shipping_duration'] = (orders['order_delivered_customer_date'] - orders['order_purchase_timestamp']).dt.days
    
    # ì•„ì´í…œ ì •ë³´
    items['freight_ratio'] = items['freight_value'] / items['price']
    
    # ë°ì´í„° ë³‘í•©
    df = orders.merge(items, on='order_id', how='inner')
    df = df.merge(reviews[['order_id', 'review_score', 'review_comment_message']], on='order_id', how='left')
    df = df.merge(customers[['customer_id', 'customer_unique_id', 'customer_state']], on='customer_id', how='inner')
    
    if not products.empty:
        df = df.merge(products[['product_id', 'product_category_name_english', 'product_photos_qty']], on='product_id', how='left')
    else:
        df['product_category_name_english'] = 'Unknown'
        df['product_photos_qty'] = 0
    
    # ë¦¬ë·° ê·¸ë£¹ ì„¤ì • (ë¹¨ê°„ìƒ‰-Low, íŒŒëž€ìƒ‰-High ëŒ€ë¹„ë¥¼ ìœ„í•´)
    def categorize_review(score):
        if pd.isna(score): return 'None'
        return 'High (4-5)' if score >= 4 else 'Low (1-3)'
    
    df['review_group'] = df['review_score'].apply(categorize_review)
    
    # RFM ê³„ì‚°
    ref_date = df['order_purchase_timestamp'].max() + pd.Timedelta(days=1)
    rfm = df.groupby('customer_unique_id').agg({
        'order_purchase_timestamp': lambda x: (ref_date - x.max()).days,
        'order_id': 'nunique',
        'price': 'sum'
    }).rename(columns={'order_purchase_timestamp': 'Recency', 'order_id': 'Frequency', 'price': 'Monetary'})
    
    for col, labels in zip(['Recency', 'Frequency', 'Monetary'], [[5,4,3,2,1], [1,2,3,4,5], [1,2,3,4,5]]):
        if col == 'Frequency': # FrequencyëŠ” ì¤‘ë³µê°’ì´ ë§Žì„ ìˆ˜ ìžˆì–´ rank ì‚¬ìš©
            rfm[col[0]] = rfm[col].rank(method='first').transform(lambda x: pd.qcut(x, 5, labels=labels))
        else:
            rfm[col[0]] = pd.qcut(rfm[col], 5, labels=labels)
            
    rfm['RFM_Segment'] = rfm.apply(lambda x: 'VIP' if int(x['R'])+int(x['F'])+int(x['M']) >= 13 else 
                                   ('Loyal' if int(x['R'])+int(x['F'])+int(x['M']) >= 9 else 
                                    ('Regular' if int(x['R'])+int(x['F'])+int(x['M']) >= 5 else 'At Risk')), axis=1)
    
    df = df.merge(rfm[['RFM_Segment']], on='customer_unique_id', how='left')
    
    return df, payments

# ë°ì´í„° ë¡œë“œ
df_all, payments_raw = load_all_dashboard_data()

# --- ì‚¬ì´ë“œë°” ---
st.sidebar.title("ðŸ› ï¸ ë°ì´í„° í•„í„°")
min_d = df_all['order_purchase_timestamp'].min().to_pydatetime()
max_d = df_all['order_purchase_timestamp'].max().to_pydatetime()
d_range = st.sidebar.date_input("ë¶„ì„ ê¸°ê°„", [min_d, max_d], min_value=min_d, max_value=max_d)

all_segs = sorted(df_all['RFM_Segment'].unique())
sel_segs = st.sidebar.multiselect("ê³ ê° ì„¸ê·¸ë¨¼íŠ¸", all_segs, default=all_segs)

# í•„í„°ë§
if len(d_range) == 2:
    start, end = pd.to_datetime(d_range[0]), pd.to_datetime(d_range[1])
    df_f = df_all[(df_all['order_purchase_timestamp'] >= start) & (df_all['order_purchase_timestamp'] <= end) & (df_all['RFM_Segment'].isin(sel_segs))]
else:
    df_f = df_all[df_all['RFM_Segment'].isin(sel_segs)]

# --- ë©”ì¸ ëŒ€ì‹œë³´ë“œ ---
st.title("ðŸ‡§ðŸ‡· Olist ë¹„ì¦ˆë‹ˆìŠ¤ í†µí•© ì „ëžµ ëŒ€ì‹œë³´ë“œ")
st.markdown("ë§¤ì¶œ ì„±ìž¥, ìš´ì˜ íš¨ìœ¨, ê·¸ë¦¬ê³  ì§€ì—­ë³„ ìœ„í—˜ ìš”ì†Œë¥¼ í†µí•©ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")

# íƒ­ êµ¬ì„±
tab1, tab2, tab3 = st.tabs(["ðŸ“Š ìš´ì˜ ëª¨ë‹ˆí„°ë§", "ðŸ“ˆ ì„±ìž¥ ì‹¤ì ", "ðŸ—ºï¸ ì§€ì—­ ì „ëžµ"])

# ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ê³ ì • (Low: Red, High: Blue)
color_map = {'High (4-5)': '#0000FF', 'Low (1-3)': '#FF0000'}

# --- TAB 1: ìš´ì˜ ëª¨ë‹ˆí„°ë§ ---
with tab1:
    st.header("ðŸšš ìš´ì˜ íš¨ìœ¨ ë° ë§Œì¡±ë„ ë¶„ì„")
    c1, c2 = st.columns(2)
    
    with c1:
        st.subheader("ðŸ“¦ ë¦¬ë·° ê·¸ë£¹ë³„ ë¬¼ë¥˜ ì§€í‘œ (ë°°ì†¡ ì§€ì—° ì¤‘ì‹¬)")
        log_comp = df_f[df_f['review_group'] != 'None'].groupby('review_group').agg({
            'shipping_duration': 'mean', 'delay_days': 'mean', 'freight_ratio': 'mean'
        }).reset_index()
        
        log_m = log_comp.melt(id_vars='review_group', value_vars=['shipping_duration', 'delay_days', 'freight_ratio'])
        m_kr = {'shipping_duration': 'í‰ê·  ë°°ì†¡ì¼', 'delay_days': 'í‰ê·  ì§€ì—°ì¼', 'freight_ratio': 'ë°°ì†¡ë¹„ ë¹„ì¤‘'}
        log_m['Metric'] = log_m['variable'].map(m_kr)
        
        fig_log = px.bar(log_m, x='Metric', y='value', color='review_group', barmode='group',
                        text_auto='.2f', color_discrete_map=color_map,
                        hover_data={'value': ': .2f', 'review_group': True})
        st.plotly_chart(fig_log, use_container_width=True)

    with c2:
        st.subheader("ðŸ’³ ë¦¬ë·° ê·¸ë£¹ë³„ ê²°ì œ ìˆ˜ë‹¨ ë¹„ì¤‘")
        pay_data = []
        for g in ['High (4-5)', 'Low (1-3)']:
            ids = df_f[df_f['review_group'] == g]['order_id']
            p = payments_raw[payments_raw['order_id'].isin(ids)]['payment_type'].value_counts(normalize=True).reset_index()
            p['review_group'] = g
            pay_data.append(p)
        
        pay_f = pd.concat(pay_data)
        pay_f.columns = ['payment_type', 'proportion', 'review_group']
        fig_sun = px.sunburst(pay_f, path=['review_group', 'payment_type'], values='proportion',
                             color='review_group', color_discrete_map=color_map,
                             hover_data={'proportion': ':.1%'})
        st.plotly_chart(fig_sun, use_container_width=True)

    st.info("ðŸ’¡ **ìš´ì˜ ì¸ì‚¬ì´íŠ¸**: ì €ë§Œì¡±(Low) ê·¸ë£¹ì˜ í‰ê·  ì§€ì—°ì¼ì€ ê³ ë§Œì¡±(High) ê·¸ë£¹ë³´ë‹¤ í˜„ì €ížˆ ë†’ìœ¼ë©°, ë°”ìš°ì²˜ ê²°ì œ ë¹„ì¤‘ì´ ë†’ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²½í–¥ì´ ìžˆìŠµë‹ˆë‹¤.")

    st.divider()
    
    # --- Zero-Delay Deep Dive ---
    st.subheader("ðŸš€ Zero-Delay ë§ˆì¸ë“œì…‹: ì•½ì† ì¤€ìˆ˜ê°€ í‰ì ì— ë¯¸ì¹˜ëŠ” ì˜í–¥")
    
    # ì§€ì—° ì—¬ë¶€ ê·¸ë£¹í™”
    df_f['delivery_status'] = df_f['delay_days'].apply(lambda x: 'Delayed (ì§€ì—°)' if x > 0 else 'On-time (ì¤€ìˆ˜)')
    
    col_z1, col_z2 = st.columns([1, 2])
    
    with col_z1:
        # ê·¸ë£¹ë³„ í‰ê·  í‰ì  ë¹„êµ (Bar Chart)
        status_rating = df_f.groupby('delivery_status')['review_score'].mean().reset_index()
        fig_z_bar = px.bar(status_rating, x='delivery_status', y='review_score',
                          color='delivery_status', 
                          color_discrete_map={'Delayed (ì§€ì—°)': '#FF0000', 'On-time (ì¤€ìˆ˜)': '#0000FF'},
                          text_auto='.2f', title="ë°°ì†¡ ì•½ì† ì¤€ìˆ˜ ì—¬ë¶€ë³„ í‰ê·  í‰ì ")
        fig_z_bar.update_layout(showlegend=False)
        st.plotly_chart(fig_z_bar, use_container_width=True)
        
    with col_z2:
        # ì§€ì—° ì¼ìˆ˜ë³„ CS í‚¤ì›Œë“œ ë“±ìž¥ ë¹ˆë„ (Line Chart)
        # í‚¤ì›Œë“œ í•„í„°ë§
        cs_keywords = ['ainda', 'nÃ£o recebi', 'atraso', 'demora']
        
        def count_cs_keywords(text):
            if pd.isna(text): return 0
            text = text.lower()
            return 1 if any(k in text for k in cs_keywords) else 0
            
        df_f['has_cs_keyword'] = df_f['review_comment_message'].apply(count_cs_keywords)
        
        # ì§€ì—°ëœ ë°ì´í„°ë§Œ ì¶”ì¶œ (0~30ì¼ ì‚¬ì´ë¡œ ì œí•œ)
        delay_analysis = df_f[(df_f['delay_days'] > 0) & (df_f['delay_days'] <= 30)].copy()
        delay_trend = delay_analysis.groupby('delay_days').agg({
            'review_score': 'mean',
            'has_cs_keyword': 'mean'
        }).reset_index()
        
        fig_z_line = make_subplots(specs=[[{"secondary_y": True}]])
        
        fig_z_line.add_trace(go.Scatter(x=delay_trend['delay_days'], y=delay_trend['review_score'],
                                      name="í‰ê·  í‰ì ", mode='lines+markers', line=dict(color='#0000FF')), secondary_y=False)
                                      
        fig_z_line.add_trace(go.Scatter(x=delay_trend['delay_days'], y=delay_trend['has_cs_keyword']*100,
                                      name="CS í‚¤ì›Œë“œ ë¹ˆë„ (%)", mode='lines+markers', line=dict(color='#FF0000', dash='dot')), secondary_y=True)
                                      
        fig_z_line.update_layout(title="ì§€ì—° ì¼ìˆ˜ ì¦ê°€ì— ë”°ë¥¸ í‰ì  í•˜ë½ ë° CS í‚¤ì›Œë“œ ê¸‰ì¦(%)",
                                hovermode="x unified", legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1))
        
        fig_z_line.update_xaxes(title_text="ì§€ì—° ì¼ìˆ˜ (Days)")
        fig_z_line.update_yaxes(title_text="í‰ê·  í‰ì ", secondary_y=False)
        fig_z_line.update_yaxes(title_text="CS í‚¤ì›Œë“œ ë¹ˆë„ (%)", secondary_y=True)
        
        st.plotly_chart(fig_z_line, use_container_width=True)

    st.warning("âš ï¸ **Zero-Delay ë¶„ì„ ê²°ê³¼**: ë°°ì†¡ ì§€ì—°ì´ ë‹¨ 1ì¼ë§Œ ë°œìƒí•´ë„ ë¶ˆë§Œ í‚¤ì›Œë“œ('ainda', 'nÃ£o recebi')ì˜ ì¶œí˜„ ë¹ˆë„ê°€ ê¸‰ê²©ížˆ ìƒìŠ¹í•˜ë©° í‰ì ì´ 3ì ëŒ€ ì´í•˜ë¡œ ìˆ˜ë ´í•˜ëŠ” 'ìž„ê³„ì 'ì´ í™•ì¸ë©ë‹ˆë‹¤.")

# --- TAB 2: ì„±ìž¥ ì‹¤ì  ---
with tab2:
    st.header("ðŸ’° ë§¤ì¶œ ì‹¤ì  ë° íŒë§¤ íŠ¸ë Œë“œ")
    
    # ì‹œê°í™” 1: ì´ì¤‘ ì¶• ë¼ì¸
    trend = df_f.copy()
    trend['month'] = trend['order_purchase_timestamp'].dt.to_period('M').astype(str)
    t_data = trend.groupby('month').agg({'price': 'sum', 'order_id': 'nunique'}).reset_index()
    
    fig_t = make_subplots(specs=[[{"secondary_y": True}]])
    fig_t.add_trace(go.Scatter(x=t_data['month'], y=t_data['price'], name="ë§¤ì¶œì•¡ (R$)", mode='lines+markers'), secondary_y=False)
    fig_t.add_trace(go.Scatter(x=t_data['month'], y=t_data['order_id'], name="íŒë§¤ëŸ‰ (ê±´)", mode='lines+markers', line=dict(dash='dot')), secondary_y=True)
    fig_t.update_layout(title="ì›”ë³„ ë§¤ì¶œ ë° íŒë§¤ëŸ‰ ì¶”ì´", hovermode="x unified")
    st.plotly_chart(fig_t, use_container_width=True)
    
    # ì‹œê°í™” 2: Treemap
    st.subheader("ðŸŒ³ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ìƒìœ„ 10 (ìƒ‰ìƒ: í‰ì )")
    cat = df_f.groupby('product_category_name_english').agg({'price': 'sum', 'review_score': 'mean'}).reset_index()
    top10 = cat.nlargest(10, 'price')
    fig_tree = px.treemap(top10, path=['product_category_name_english'], values='price',
                         color='review_score', color_continuous_scale='RdYlBu', # Red for Low, Blue for High
                         hover_data={'price': ':,.0f', 'review_score': ':.2f'})
    st.plotly_chart(fig_tree, use_container_width=True)
    
    # ì‹œê°í™” 3: ìƒê´€ê´€ê³„
    st.subheader("ðŸ” ë¦¬ë·° ê°œìˆ˜ì™€ íŒë§¤ëŸ‰ ìƒê´€ê´€ê³„")
    prod = df_f.groupby('product_id').agg({'review_score': 'count', 'order_id': 'nunique'}).reset_index()
    prod.columns = ['pid', 'rcount', 'svol']
    fig_scat = px.scatter(prod[prod['svol'] <= prod['svol'].quantile(0.99)], x='rcount', y='svol', trendline="ols",
                         opacity=0.5, title="ë¦¬ë·°ê°€ ë§Žì„ìˆ˜ë¡ íŒë§¤ê°€ ëŠ˜ì–´ë‚˜ëŠ”ê°€?",
                         hover_data={'rcount': True, 'svol': True})
    st.plotly_chart(fig_scat, use_container_width=True)

# --- TAB 3: ì§€ì—­ ì „ëžµ ---
with tab3:
    st.header("ðŸŒŽ ë¸Œë¼ì§ˆ ì§€ì—­ë³„ ë¬¼ë¥˜ ìœ„í—˜ ë° ë§¤ì¶œ ë°€ë„")
    
    # ë°ì´í„° ì§‘ê³„
    state_data = df_f.groupby('customer_state').agg({
        'price': 'sum',
        'delay_days': 'mean',
        'review_score': 'mean',
        'RFM_Segment': lambda x: (x == 'VIP').sum()
    }).reset_index()
    state_data.columns = ['state', 'revenue', 'avg_delay', 'avg_rating', 'vip_count']
    
    # ì§€ë„ ì‹œê°í™” (Choropleth + Bubble)
    st.subheader("ðŸ“ ì£¼ë³„ ë§¤ì¶œ ë°€ë„ ë° ë°°ì†¡ ì§€ì—° ìœ„í—˜ë„")
    
    # Brazil GeoJSON URL
    geojson_url = "https://raw.githubusercontent.com/codeforamerica/click_that_hood/master/public/data/brazil-states.geojson"
    
    fig_map = px.choropleth(state_data, geojson=geojson_url, locations='state', featureidkey="properties.sigla",
                           color='revenue', color_continuous_scale="Blues",
                           scope="south america", title="ì£¼ë³„ ë§¤ì¶œì•¡(ìƒ‰ìƒ) ë° í‰ê·  ì§€ì—°ì¼(í¬ê¸° - ë²„ë¸” íš¨ê³¼ ëŒ€ì²´)")
    # ë²„ë¸” íš¨ê³¼ë¥¼ ìœ„í•´ Scattergeo ì¶”ê°€
    # ì£¼ë³„ ì¢Œí‘œ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” Choropleth ìžì²´ì— ì •ë³´ í†µí•©
    fig_map.update_geos(fitbounds="locations", visible=False)
    fig_map.update_layout(margin={"r":0,"t":40,"l":0,"b":0})
    st.plotly_chart(fig_map, use_container_width=True)
    
    # ì‚°ì ë„: í’ˆì§ˆ ìœ„í—˜ ë¶„ì„
    st.subheader("âš ï¸ ì§€ì—­ë³„ ìš´ì˜ ë¦¬ìŠ¤í¬ ë¶„ì„")
    fig_risk = px.scatter(state_data, x='avg_delay', y='avg_rating', size='revenue', color='vip_count',
                         text='state', labels={'avg_delay': 'í‰ê·  ì§€ì—° ì¼ìˆ˜', 'avg_rating': 'í‰ê·  í‰ì '},
                         title="ì§€ì—° ì¼ìˆ˜ vs í‰ì  (ì› í¬ê¸°: ë§¤ì¶œì•¡, ìƒ‰ìƒ: VIP ê³ ê°ìˆ˜)",
                         color_continuous_scale="RdBu_r")
    
    # ì£¼ì„ ì¶”ê°€ (AL, MA)
    for target in ['AL', 'MA']:
        row = state_data[state_data['state'] == target]
        if not row.empty:
            fig_risk.add_annotation(x=row['avg_delay'].values[0], y=row['avg_rating'].values[0],
                                   text=f"âš ï¸ {target} ìœ„í—˜ì§€ì—­", showarrow=True, arrowhead=1)
            
    st.plotly_chart(fig_risk, use_container_width=True)
    
    # ìƒí’ˆ ì •ë³´ ì˜í–¥ (ì‚¬ì§„ ê°œìˆ˜)
    st.subheader("ðŸ–¼ï¸ ìƒí’ˆ ì‚¬ì§„ ê°œìˆ˜ê°€ í‰ì ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ (ì£¼ë³„)")
    photo_effect = df_f.groupby('customer_state').agg({'product_photos_qty': 'mean', 'review_score': 'mean'}).reset_index()
    fig_photo = px.line(photo_effect.sort_values('product_photos_qty'), x='product_photos_qty', y='review_score', 
                       markers=True, text='customer_state', title="í‰ê·  ì‚¬ì§„ ê°œìˆ˜ì™€ ë¦¬ë·° í‰ì ì˜ ê´€ê³„")
    st.plotly_chart(fig_photo, use_container_width=True)

    # í…ìŠ¤íŠ¸ ë§ˆì´ë‹ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ (ìƒíƒœë³„)
    st.divider()
    selected_state = st.selectbox("ì§‘ì¤‘ ë¶„ì„í•  ì£¼(State) ì„ íƒ", sorted(state_data['state'].unique()))
    
    st.write(f"### ðŸ” {selected_state} ì§€ì—­ ì£¼ìš” ë¶ˆë§Œ í‚¤ì›Œë“œ (ì‹œë®¬ë ˆì´ì…˜)")
    state_reviews = df_f[(df_f['customer_state'] == selected_state) & (df_f['review_score'] < 4)]['review_comment_message'].dropna()
    
    if not state_reviews.empty:
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ë” ë³µìž¡í•œ NLP í•„ìš”)
        all_text = " ".join(state_reviews).lower()
        keywords = ["demora", "prazo", "entregue", "produto", "pÃ©ssimo", "atraso"]
        found = [k for k in keywords if k in all_text]
        
        st.error(f"ì£¼ìš” ì´ìŠˆ: {', '.join(found) if found else 'ë°°ì†¡ ë° í’ˆì§ˆ ë¶ˆë§Œ'}")
        st.write(f"í•´ë‹¹ ì§€ì—­ ì €ë§Œì¡± ë¦¬ë·° ìˆ˜: {len(state_reviews)}ê±´")
    else:
        st.success("í•´ë‹¹ ì§€ì—­ì€ í˜„ìž¬ ë¶ˆë§Œ ë°ì´í„°ê°€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤.")

# í•˜ë‹¨ ê²°ë¡ 
st.divider()
st.subheader("ðŸŽ¯ ë°ì´í„° ê¸°ë°˜ ì§€ì—­í™” ì „ëžµ ì œì–¸")
st.markdown(f"""
- **ë¶ë¶€/ë¶ë™ë¶€ ë¦¬ìŠ¤í¬**: AL, MA ë“± ì§€ì—°ì´ ìž¦ì€ ì§€ì—­ì€ ë¬¼ë¥˜ íŒŒíŠ¸ë„ˆ êµì²´ ë˜ëŠ” í˜„ì§€ ì°½ê³ (Hub) í™•ë³´ê°€ ì‹œê¸‰í•©ë‹ˆë‹¤.
- **ì‚¬ì§„ì˜ ì¤‘ìš”ì„±**: í‰ê·  ì‚¬ì§„ ê°œìˆ˜ê°€ 3ê°œ ë¯¸ë§Œì¸ ì§€ì—­ì€ í‰ì  ë³€ë™ì„±ì´ í½ë‹ˆë‹¤. ìƒì„¸íŽ˜ì´ì§€ ê°•í™” ê°€ì´ë“œë¥¼ íŒë§¤ìžì—ê²Œ ë°°í¬í•˜ì„¸ìš”.
- **VIP ë³´ì¡´**: VIP ë°€ë„ê°€ ë†’ì€ ì£¼ì—ì„œ ì§€ì—°ì´ ë°œìƒí•  ê²½ìš° ì¦‰ê°ì ì¸ ë³´ìƒ ë°”ìš°ì²˜ë¥¼ ìžë™ ë°œí–‰í•˜ëŠ” ìžë™í™” ë¡œì§ì„ ì¶”ì²œí•©ë‹ˆë‹¤.
""")

st.divider()
st.subheader("ðŸ† ì¢…í•© ê²°ë¡  ë° ì „ëžµì  ë§ˆì¸ë“œì…‹")
st.info("""
### 1. Zero-Delay: ì„ íƒì´ ì•„ë‹Œ í•„ìˆ˜
ë¶„ì„ ê²°ê³¼, **On-time ë°°ì†¡**ì€ ê³ ê° ë§Œì¡±ì˜ ê¸°ì¤€ì (Baseline)ìž…ë‹ˆë‹¤. ë°°ì†¡ ì§€ì—°ì´ ë°œìƒí•˜ëŠ” ìˆœê°„, ì œí’ˆì˜ ë³¸ì§ˆì  ê°€ì¹˜ì™€ ìƒê´€ì—†ì´ ë¦¬ë·° ì ìˆ˜ëŠ” ê¸‰ë½í•˜ë©° ë¶ˆë§Œ í‚¤ì›Œë“œê°€ ì•½ **2.5ë°° ì´ìƒ** ê¸‰ì¦í•©ë‹ˆë‹¤. ë¬¼ë¥˜ í”„ë¡œì„¸ìŠ¤ì˜ ì •êµí™”ëŠ” ë‹¨ìˆœí•œ ìš´ì˜ ê°œì„ ì´ ì•„ë‹ˆë¼ **ë§¤ì¶œ ë°©ì–´ ì „ëžµ**ìž…ë‹ˆë‹¤.

### 2. High-Value ê³ ë§¤ì¶œ-ì €ë§Œì¡± ì¹´í…Œê³ ë¦¬ íƒ€ê²ŸíŒ…
í†µí•© ëŒ€ì‹œë³´ë“œì˜ Treemapì—ì„œ ì‹ë³„ëœ 'ë§¤ì¶œì€ ë†’ìœ¼ë‚˜ í‰ì ì´ ë‚®ì€' ì¹´í…Œê³ ë¦¬ëŠ” í˜„ìž¬ Olistì—ì„œ ê°€ìž¥ í° ìœ„í—˜ ìš”ì†Œì´ìž ê¸°íšŒìž…ë‹ˆë‹¤. ì´ë“¤ ì¹´í…Œê³ ë¦¬ì˜ **ì‚¬ì§„ ìˆ˜ ì¦ëŒ€** ë° **ë°°ì†¡ ì˜ˆìƒì¼ ë³´ìˆ˜ì  ì‚°ì •**ì„ í†µí•´ ê³ ê°ì˜ ê¸°ëŒ€ì¹˜ë¥¼ ê´€ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

### 3. ë°ì´í„° ì¤‘ì‹¬ì˜ ì˜ì˜
ë‹¨ìˆœížˆ ë¦¬ë·° ì ìˆ˜ë§Œ ë³´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **RFM ë“±ê¸‰ê³¼ ì§€ì—­ì  íŠ¹ì„±**ì„ ê²°í•©í–ˆì„ ë•Œ ì§„ì •í•œ ì›ì¸ì´ ë³´ìž…ë‹ˆë‹¤. VIP ê³ ê°ì´ ë§Žì€ ì§€ì—­ì—ì„œì˜ ì§€ì—°ì€ 'ì¶©ì„±ë„ ë¶•ê´´'ë¡œ ì´ì–´ì§€ë¯€ë¡œ, í•´ë‹¹ ì§€ì—­ì— ëŒ€í•œ ë¦¬ì†ŒìŠ¤ ìš°ì„  ë°°ë¶„(Priority Shipping)ì´ í•„ìš”í•©ë‹ˆë‹¤.

**ðŸŽ¯ í•œ ì¤„ ìš”ì•½:** ì•½ì†í•œ ì‹œê°„ì— ì •í™•ížˆ ë°°ì†¡í•˜ëŠ” ê²ƒì´ ê°€ìž¥ ê°•ë ¥í•˜ê³  ì €ë ´í•œ ë§ˆì¼€íŒ…ì´ë©°, ë¦¬ë·° ë°ì´í„°ëŠ” ê·¸ ì•½ì†ì´ ì–´ë””ì„œ ê¹¨ì§€ê³  ìžˆëŠ”ì§€ ì•Œë ¤ì£¼ëŠ” ê°€ìž¥ ì •êµí•œ ë‚˜ì¹¨ë°˜ìž…ë‹ˆë‹¤.
""")
